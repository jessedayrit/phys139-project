{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T21:47:00.950308Z",
     "start_time": "2025-11-19T21:46:57.830209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import pymatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define a simple NN model (adjust layers for your data dimensions)\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=X_train.shape[1:]),  # Flatten events\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(y_train.shape[1], activation='sigmoid')  # Output err_signal (binary)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b872d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logical_error_rate(model, X, y_true, parities):\n",
    "    predictions = (model.predict(X) > 0.5).astype(bool)  # Threshold predictions\n",
    "    errors = 0\n",
    "    for pred, true, parity in zip(predictions, y_true, parities):\n",
    "        # Check if predicted err_signal leads to correct parity (simplified)\n",
    "        if not np.array_equal(pred, true):  # If mismatch, count as error\n",
    "            errors += 1\n",
    "    return errors / len(X)\n",
    "\n",
    "parities_test = [d[5] for d in test_data]\n",
    "ler_nn = compute_logical_error_rate(model, X_test, y_test, parities_test)\n",
    "print(f\"NN Logical Error Rate: {ler_nn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0214de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parity check matrix for surface code (distance 3, simplified)\n",
    "# For a distance 3 surface code, the PCM has rows for X and Z stabilizers\n",
    "# This is a basic example; adjust for your exact layout from circuit_model.py\n",
    "H = np.array([\n",
    "    [1, 0, 1, 0, 1, 0, 0, 0, 0],  # Example row for X stabilizer\n",
    "    # Add more rows for full PCM (9 data qubits for dist=3)\n",
    "    # ... (full H matrix here, based on surface code geometry)\n",
    "])\n",
    "# For simplicity, assume H is predefined; in practice, generate from SurfaceCode class\n",
    "\n",
    "matcher = pymatching.Matching(H)\n",
    "\n",
    "def decode_with_mwpm(syndromes, distance=3):\n",
    "    # syndromes is a 1D array of defect positions\n",
    "    # Convert to pymatching format\n",
    "    syndrome_array = np.array(syndromes, dtype=int)\n",
    "    predicted_errors = matcher.decode(syndrome_array)\n",
    "    return predicted_errors  # Binary array of predicted flips\n",
    "\n",
    "# Evaluate MWPM on test data\n",
    "def compute_logical_error_rate_mwpm(data, distance=3):\n",
    "    errors = 0\n",
    "    for d in data:\n",
    "        syndromes = d[1]  # syndromes array\n",
    "        true_parity = d[5]  # true parity\n",
    "        predicted_errors = decode_with_mwpm(syndromes[-1], distance)  # Use final syndrome\n",
    "        # Compute predicted parity from predicted errors (simplified: parity of error flips)\n",
    "        pred_parity = np.sum(predicted_errors) % 2\n",
    "        if pred_parity != true_parity:\n",
    "            errors += 1\n",
    "    return errors / len(data)\n",
    "\n",
    "ler_mwpm = compute_logical_error_rate_mwpm(test_data)\n",
    "print(f\"MWPM Logical Error Rate: {ler_mwpm}\")\n",
    "\n",
    "# Compare\n",
    "print(f\"NN LER: {ler_nn}, MWPM LER: {ler_mwpm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999642e6ccde919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pull (Dylan)\n",
    "#Johnny's Test pull\n",
    "# Jesse's Test pull"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
