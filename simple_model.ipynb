{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "026b0697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:47:43.897351Z",
     "start_time": "2025-12-09T00:47:43.895484Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.src.callbacks import EarlyStopping\n",
    "\n",
    "from database_io import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from scipy import optimize as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8fdd65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:47:45.393578Z",
     "start_time": "2025-12-09T00:47:45.390269Z"
    }
   },
   "outputs": [],
   "source": [
    "# path of databases (must exist)\n",
    "db_path = \"db/\"\n",
    "\n",
    "# filenames of databases (this must be sqlite3 databases)\n",
    "train_fname = \"surf17_train.db\"\n",
    "validation_fname = \"surf17_validation.db\"\n",
    "test_fname = \"surf17_test.db\"\n",
    "\n",
    "dim_syndr = 8\n",
    "dim_fsyndr = 4\n",
    "n_steps_net1 = 20\n",
    "n_steps_net2 = 3\n",
    "\n",
    "data = DatabaseIO(dim_syndr, dim_fsyndr, n_steps_net1, n_steps_net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec982d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T00:47:47.076955Z",
     "start_time": "2025-12-09T00:47:46.121430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded databases and checked exclusiveness training, validation, and test keys\n",
      "N_training=400000, N_validaiton=10000, N_test=5000.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data.close_databases()\n",
    "except:\n",
    "    pass\n",
    "data.load_data(db_path + train_fname, db_path + validation_fname, db_path + test_fname)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "n_batches_train = 1000\n",
    "n_batches_validation = 100\n",
    "\n",
    "\n",
    "\n",
    "class DecoderSequence(Sequence):\n",
    "    def __init__(self, data, batch_size, n_batches, data_type):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = n_batches\n",
    "        self.data_type = data_type\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return the idx-th batch captured at epoch start\n",
    "        return self.epoch_batches[idx]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Called automatically by Keras at the end of each epoch.\"\"\"\n",
    "        gen = self.data.gen_batches(\n",
    "            self.batch_size,\n",
    "            self.n_batches,\n",
    "            data_type=self.data_type\n",
    "        )\n",
    "\n",
    "        self.epoch_batches = []\n",
    "        for _ in range(self.n_batches):\n",
    "            batch_x1, batch_x2, batch_fx, batch_l1, batch_l2, batch_y = next(gen)\n",
    "\n",
    "            # Wrap into Keras multi-input format\n",
    "            inputs = (batch_x1, batch_x2, batch_fx) #, batch_l1, batch_l2)\n",
    "            outputs = batch_y\n",
    "            self.epoch_batches.append((inputs, outputs))\n",
    "\n",
    "train_seq = DecoderSequence(\n",
    "    data,\n",
    "    batch_size=batch_size,\n",
    "    n_batches=n_batches_train,\n",
    "    data_type='training'\n",
    ")\n",
    "\n",
    "val_seq = DecoderSequence(\n",
    "    data,\n",
    "    batch_size=batch_size,\n",
    "    n_batches=n_batches_validation,\n",
    "    data_type='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b03a6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ x2_recent[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ masking_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ any_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ final_increment[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,416</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ x1_full[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_5 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ x1_full[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_5 (\u001b[38;5;33mAny\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m18,688\u001b[0m │ x2_recent[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m18,688\u001b[0m │ masking_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ any_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lstm_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_23 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m33,024\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m33,024\u001b[0m │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ any_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ final_increment[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,416\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ p1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ p2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ p1_prob[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ p2_prob[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,130</span> (438.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,130\u001b[0m (438.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,130</span> (438.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m112,130\u001b[0m (438.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEFINING THE MODEL\n",
    "x1 = Input(shape=(None, dim_syndr), name=\"x1_full\")\n",
    "x2 = Input(shape=(n_steps_net2, dim_syndr), name=\"x2_recent\")\n",
    "fx = Input(shape=(dim_fsyndr,), name=\"final_increment\")\n",
    "\n",
    "x1_masked = layers.Masking(mask_value=0.0)(x1)\n",
    "\n",
    "dropout_rate = 0.2\n",
    "layer_width = 64\n",
    "\n",
    "# Network 1 (full syndrome history)\n",
    "h1 = layers.LSTM(layer_width, activation=\"tanh\", return_sequences=True, kernel_regularizer=keras.regularizers.l2(1e-5))(x1_masked)\n",
    "h1 = layers.Dropout(dropout_rate)(h1)\n",
    "h1 = layers.LSTM(layer_width, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5))(h1)\n",
    "h1 = layers.Dropout(dropout_rate)(h1)\n",
    "p1 = layers.Dense(layer_width, activation=\"relu\", name=\"p1\", kernel_regularizer=keras.regularizers.l2(1e-5))(h1)\n",
    "p1 = layers.Dropout(dropout_rate)(p1)\n",
    "p1 = layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.l2(1e-5), name=\"p1_prob\")(p1)\n",
    "\n",
    "\n",
    "# Network 2 (recent syndrome + final increment)\n",
    "h2 = layers.LSTM(layer_width, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5), return_sequences=True)(x2)\n",
    "h2 = layers.Dropout(dropout_rate)(h2)\n",
    "h2 = layers.LSTM(layer_width, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5))(h2)\n",
    "h2 = layers.Dropout(dropout_rate)(h2)\n",
    "\n",
    "p2 = layers.Concatenate()([h2, fx])\n",
    "p2 = layers.Dense(layer_width, activation=\"relu\", name=\"p2\", kernel_regularizer=keras.regularizers.l2(1e-5))(p2)\n",
    "p2 = layers.Dropout(dropout_rate)(p2)\n",
    "p2 = layers.Dense(1, activation=\"sigmoid\", name=\"p2_prob\", kernel_regularizer=keras.regularizers.l2(1e-5))(p2)\n",
    "\n",
    "\n",
    "# Final combination p = probabilistic sum\n",
    "p_final = layers.Lambda(lambda x: x[0]*(1-x[1]) + x[1]*(1-x[0]))([p1, p2]) # XOR Gate\n",
    "\n",
    "model = Model(inputs=[x1, x2, fx], outputs=p_final)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56560b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:26:15.840995Z",
     "start_time": "2025-12-09T00:47:47.664840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacky\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer \"functional_5\" expects 3 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(None, 20, 8) dtype=bool>, <tf.Tensor 'data_1:0' shape=(None, 3, 8) dtype=bool>, <tf.Tensor 'data_2:0' shape=(None, 4) dtype=bool>, <tf.Tensor 'data_3:0' shape=(None,) dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     10\u001b[39m checkpoint = ModelCheckpoint(\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_model.keras\u001b[39m\u001b[33m'\u001b[39m,        \u001b[38;5;66;03m# file path to save the model\u001b[39;00m\n\u001b[32m     12\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,    \u001b[38;5;66;03m# metric to monitor\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m                 \u001b[38;5;66;03m# 'min' for loss, 'max' for accuracy\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m early_stop = EarlyStopping(\n\u001b[32m     19\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,        \u001b[38;5;66;03m# use validation loss to monitor\u001b[39;00m\n\u001b[32m     20\u001b[39m     patience=\u001b[32m50\u001b[39m,                \u001b[38;5;66;03m# stop after n epochs with no improvement\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_batches_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_batches_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacky\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacky\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:160\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    158\u001b[39m inputs = tree.flatten(inputs)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) != \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    161\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLayer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m input(s),\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m input tensors. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Layer \"functional_5\" expects 3 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(None, 20, 8) dtype=bool>, <tf.Tensor 'data_1:0' shape=(None, 3, 8) dtype=bool>, <tf.Tensor 'data_2:0' shape=(None, 4) dtype=bool>, <tf.Tensor 'data_3:0' shape=(None,) dtype=int32>]"
     ]
    }
   ],
   "source": [
    "# COMPILING AND TRAINING THE MODEL\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',        # file path to save the model\n",
    "    monitor='val_accuracy',    # metric to monitor\n",
    "    verbose=1,                 # prints message when saving\n",
    "    save_best_only=True,       # only save if improved\n",
    "    mode='max'                 # 'min' for loss, 'max' for accuracy\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # use validation loss to monitor\n",
    "    patience=50,                # stop after n epochs with no improvement\n",
    "    min_delta=1e-4,            # threshold for minimum change over epochs -> \"no imporovement\"\n",
    "    restore_best_weights=True, # keeps weights from the best epoch\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "results = model.fit(\n",
    "    train_seq,\n",
    "    steps_per_epoch=n_batches_train,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1,\n",
    "    validation_data=val_seq,\n",
    "    validation_steps=n_batches_validation,\n",
    "    callbacks=[checkpoint, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab553c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:26:27.177300Z",
     "start_time": "2025-12-09T01:26:26.221056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m969/969\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 78ms/step\n"
     ]
    }
   ],
   "source": [
    "# stat calculation taken from original code\n",
    "\n",
    "def decay(x, p_logical, x0):\n",
    "  \"\"\" This functions is used to make a exponential fit to the fidelity\n",
    "      curves \"\"\"\n",
    "  return (1 + (1 - 2 * p_logical)**(x - x0)) / 2.\n",
    "\n",
    "def calc_stats(data, n_sampling=5000, x0_max=10, verbose=False):\n",
    "    \"\"\" calculates the logical error rate and error bars \"\"\"\n",
    "\n",
    "    # since it is possible that the batch does not contain fidelities\n",
    "    # for all steps, hence we need a list with all steps for which\n",
    "    # predictions excist (we call it 'steps')\n",
    "    steps, data_nonzero = [], []\n",
    "    fids, rs_means_l, plogs_bs = [], [], []\n",
    "\n",
    "    # in the following we assume that the first step is s = 1\n",
    "    for s in range(1, len(data) + 1):\n",
    "        dat = data[s - 1]\n",
    "        if len(dat) != 0:\n",
    "            # non-trivial data points\n",
    "            steps.append(s)\n",
    "            data_nonzero.append(dat)\n",
    "            # fidelities\n",
    "            fids.append(np.mean(dat))\n",
    "\n",
    "    # fit decay curve to the non-tivial data\n",
    "    popt, pcov = optim.curve_fit(\n",
    "        decay, steps, fids, bounds=((0.0001, 0.0001), (.1, x0_max)))\n",
    "    plog, x0 = popt[0], popt[1]\n",
    "    if x0 > 0.99 * x0_max:\n",
    "        print(\"WARNING, x0 is larger than\", x0_max,\n",
    "            \"the fitting algorithm fails\")\n",
    "    if plog > .09:\n",
    "        print(\"WARNING, plog is larger than 9%, the fitting algorithm fails\")\n",
    "\n",
    "    \n",
    "\n",
    "    res_dict = {'steps': steps, 'fids': fids, 'plog': plog, 'x0': x0}\n",
    "    if verbose:\n",
    "        print(\"logical error rate:\", round(plog * 100, 5), \"%\")\n",
    "        print(\"x0 offset\", round(x0, 3))\n",
    "\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "\n",
    "batch = None\n",
    "for gen in data.gen_batches(num_samples, 1, data_type='test'):\n",
    "    batch = gen\n",
    "x1, x2, fx, l1, _, y_actual = batch\n",
    "y_prob = model.predict((x1,x2,fx,l1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf6547fe77716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501,)\n",
      "logical error rate: 0.66124 %\n",
      "x0 offset 3.797\n",
      "Accuracy: 0.6610967741935484\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQS9JREFUeJzt3Xl4U2XCNvA7e9ekG91b2lL2pUChpQiuHVEcXMcXEQXLojDgoMw3DjgKjjMjM6+vjBsjiiwuo+CCuIAoFgHB0kKh7BRKCy1t071J16RJzvdHIVgp0JSkJ8v9u65cxZOT5s4B7M1znvMciSAIAoiIiIhEIhU7ABEREXk2lhEiIiISFcsIERERiYplhIiIiETFMkJERESiYhkhIiIiUbGMEBERkahYRoiIiEhUcrEDdIXFYkFZWRn8/f0hkUjEjkNERERdIAgCGhoaEBkZCan0yuMfLlFGysrKEBMTI3YMIiIi6oaSkhJER0df8XmXKCP+/v4A2j+MWq0WOQ0RERF1hV6vR0xMjPXn+JW4RBm5eGpGrVazjBAREbmYa02x4ARWIiIiEhXLCBEREYmKZYSIiIhEZXMZ2bVrFyZNmoTIyEhIJBJs2rTpmq/ZsWMHRo4cCZVKhcTERKxbt64bUYmIiMgd2VxGmpqakJSUhBUrVnRp/6KiItx111245ZZbkJeXh6eeegqzZs3Cd999Z3NYIiIicj82X01z55134s477+zy/itXrkR8fDxeeeUVAMDAgQOxe/du/Pvf/8aECRNsfXsiIiJyMw6fM5KVlYX09PQO2yZMmICsrKwrvsZgMECv13d4EBERkXtyeBnRarUICwvrsC0sLAx6vR4tLS2dvmbZsmXQaDTWB1dfJSIicl9OeTXN4sWLodPprI+SkhKxIxEREZGDOHwF1vDwcFRUVHTYVlFRAbVaDW9v705fo1KpoFKpHB2NiIiInIDDR0bS0tKQmZnZYdu2bduQlpbm6LcmIiIiF2BzGWlsbEReXh7y8vIAtF+6m5eXh+LiYgDtp1imTZtm3X/OnDkoLCzEM888g5MnT+I///kPPvnkEzz99NP2+QRERETk0mwuI/v378eIESMwYsQIAMDChQsxYsQILFmyBABQXl5uLSYAEB8fj82bN2Pbtm1ISkrCK6+8gnfffdcpLuvdU1CNGev2obXNLHYUIiIijyURBEEQO8S16PV6aDQa6HQ6u921t9lowvh//YiaJiNuHxSGtx5Jhkx69bsKEhERUdd19ee3U15N0xN8lHKsmDoSSrkU3x+vwHObjoodiYiIyCN5bBkBgDEJwXj9oeGQSICPc4qRU1QrdiQiIiKP49FlBADuGBKBh0a3L6q26qdCkdMQERF5Ho8vIwAwa3wCAOCHExU4U9UochoiIiLPwjICoE8vP6QPDIUgAKt3F4kdh4iIyKOwjFww+8LoyOe551HTaBA5DRERkedgGbkgJT4ISdEaGEwWfLD3nNhxiIiIPAbLyAUSicQ6d+Sz3PMipyEiIvIcLCO/cGO/XgCA83UtqG82ipyGiIjIM7CM/ILGW4HowPY7CZ8obxA5DRERkWdgGfmVQRHty9UeL9eLnISIiMgzsIz8yqDIC2WkjGWEiIioJ7CM/ApHRoiIiHoWy8ivXBwZKahsgNFkETkNERGR+2MZ+ZWoAG+oveRoMws4XclJrERERI7GMvIrEomE80aIiIh6EMtIJwZFaABw3ggREVFPYBnpBEdGiIiIeg7LSCd+eUWNIAgipyEiInJvLCOdSAz1g0ImQUOrCefrWsSOQ0RE5NZYRjqhlEvRN9QfAOeNEBERORrLyBVw3ggREVHPYBm5Aq7ESkRE1DNYRq6AIyNEREQ9g2XkCgZeGBkprW+BrrlN5DRERETui2XkCjTeCkQHegPgqRoiIiJHYhm5iovzRo6V6UROQkRE5L5YRq5iSFT7svBHS1lGiIiIHIVl5CqSYgIAAHkl9aLmICIicmcsI1eRFN0+MnK2phn1zUaR0xAREbknlpGrCPBRIj7EFwBw6DxP1RARETkCy8g1XBwdySuuFzcIERGRm2IZuYaL80YOna8XNQcREZG7Yhm5huEXy0hJPQRBEDcMERGRG2IZuYaBEWooZBLUNBlxvq5F7DhERERuh2XkGrwUMuvS8LzEl4iIyP5YRrrgl6dqiIiIyL5YRrogKToAACexEhEROQLLSBdcvKLmSKkObWaLuGGIiIjcDMtIFySE+MLfS47WNgtOVTSIHYeIiMitsIx0gVQquXSqpoQrsRIREdkTy0gXJcVcWIm1pE7kJERERO6FZaSLODJCRETkGCwjXXTx8t5TlQ1oNJjEDUNERORGWEa6KFTthUiNFwQBOMI7+BIREdkNy4gNeNM8IiIi+2MZsQFXYiUiIrI/lhEbJLGMEBER2R3LiA2GRmkglQBlulaU63gHXyIiIntgGbGBr0qOIVHt641kF9aKnIaIiMg9sIzYKDU+CACQXVQjchIiIiL3wDJio9T4YAAcGSEiIrIXlhEbjY4PgkQCFFY3oVLfKnYcIiIil8cyYiONtwKDItQAgL1FHB0hIiK6Xiwj3XDpVA3njRAREV0vlpFuSE24OImVIyNERETXq1tlZMWKFYiLi4OXlxdSU1ORk5NzxX3b2trw4osvok+fPvDy8kJSUhK2bt3a7cDOICWuvYwUVDaiqsEgchoiIiLXZnMZ2bBhAxYuXIilS5fiwIEDSEpKwoQJE1BZWdnp/s899xzefvttvPHGGzh+/DjmzJmD++67DwcPHrzu8GIJ9FViQLg/ACCHoyNERETXxeYysnz5csyePRsZGRkYNGgQVq5cCR8fH6xZs6bT/T/44AM8++yzmDhxIhISEjB37lxMnDgRr7zyynWHF9OYhAvzRrjeCBER0XWxqYwYjUbk5uYiPT390jeQSpGeno6srKxOX2MwGODl5dVhm7e3N3bv3t2NuM7DuvgZ1xshIiK6LjaVkerqapjNZoSFhXXYHhYWBq1W2+lrJkyYgOXLl+P06dOwWCzYtm0bNm7ciPLy8iu+j8FggF6v7/BwNikXykh+RQNqm4wipyEiInJdDr+a5rXXXkPfvn0xYMAAKJVKzJ8/HxkZGZBKr/zWy5Ytg0ajsT5iYmIcHdNmwX4q9AvzAwDk8FQNERFRt9lURkJCQiCTyVBRUdFhe0VFBcLDwzt9Ta9evbBp0yY0NTXh3LlzOHnyJPz8/JCQkHDF91m8eDF0Op31UVJSYkvMHnNxvZG9PFVDRETUbTaVEaVSieTkZGRmZlq3WSwWZGZmIi0t7aqv9fLyQlRUFEwmEz7//HPcc889V9xXpVJBrVZ3eDgjrjdCRER0/eS2vmDhwoWYPn06Ro0ahZSUFLz66qtoampCRkYGAGDatGmIiorCsmXLAADZ2dkoLS3F8OHDUVpaihdeeAEWiwXPPPOMfT+JCC7OGzmp1aO+2YgAH6XIiYiIiFyPzWVk8uTJqKqqwpIlS6DVajF8+HBs3brVOqm1uLi4w3yQ1tZWPPfccygsLISfnx8mTpyIDz74AAEBAXb7EGIJ9fdCQi9fFFY1IaeoFrcP7vxUFREREV2ZRBAEQewQ16LX66HRaKDT6ZzulM2zXxzBR9nFmDkuHs//dpDYcYiIiJxGV39+894018m63givqCEiIuoWlpHrdHEl1uNleuha2kROQ0RE5HpYRq5TmNoLccE+sAjA/rO8qoaIiMhWLCN2cHF0hDfNIyIish3LiB2MimufN3KguE7kJERERK6HZcQOknsHAgAOndfBaLKInIaIiMi1sIzYQVywD4J8lTCaLDhWphM7DhERkUthGbEDiUSCkbEBAIDcczxVQ0REZAuWETsZeeFUDeeNEBER2YZlxE6SY9vLSO65OrjAorZEREROg2XEToZFB0AulaBCb0BpfYvYcYiIiFwGy4ideCtlGBzZvu4+540QERF1HcuIHVnnjbCMEBERdRnLiB1dXG8kl5NYiYiIuoxlxI4ulpET5Q1oMphETkNEROQaWEbsKELjjUiNF8wWAYfO14sdh4iIyCWwjNgZ540QERHZhmXEzqzzRlhGiIiIuoRlxM6SrSux1sNi4eJnRERE18IyYmcDI9TwUkiha2lDYXWT2HGIiIicHsuInSlkUiRFBwDgvBEiIqKuYBlxAM4bISIi6jqWEQfg4mdERERdxzLiACMu3MG3oLIR9c1GkdMQERE5N5YRBwjyVSKhly8A4GBxvbhhiIiInBzLiIMkx3LeCBERUVewjDgIJ7ESERF1DcuIg1wsI3kl9TCZLSKnISIicl4sIw7Sp5cf1F5ytLSZcVLbIHYcIiIip8Uy4iBSqcR60zyeqiEiIroylhEH4iRWIiKia2MZcaCL80b2FtZw3ggREdEVsIw40MjegQj2VaKywYDvj1eIHYeIiMgpsYw4kJdChodTYwEAa/cUiZyGiIjIObGMONgjY3pDLpVg39k6HDmvEzsOERGR02EZcbAwtRd+OywCAEdHiIiIOsMy0gMybogHAHx9uAyVDa0ipyEiInIuLCM9ICkmACNjA9BmFvDh3mKx4xARETkVlpEeMmNc++jIR9nnYDCZRU5DRETkPFhGesiEweGI0HihutGIrw+Vix2HiIjIabCM9BCFTIpH03oDANbsLoIgCCInIiIicg4sIz1oyuhYeCmkOF6uR05RrdhxiIiInALLSA8K9FXivhHRAIC1e86KG4aIiMhJsIz0sIwb4gAA3x/XoqS2WdwwREREToBlpIf1C/PHuMQQWATg/ayzYschIiISHcuICGaMiwMArN9XgiaDSdwwREREImMZEcHN/UIRH+KLhlYTNh44L3YcIiIiUbGMiEAqlWD6hct81+45C4uFl/kSEZHnYhkRye9GxcBfJUdhdRO+P64VOw4REZFoWEZE4qeS47ELV9b8e9tpjo4QEZHHYhkR0axxCfBXyZFf0YAtR7lEPBEReSaWERFpfBSYOb79Bnqv/nAaZo6OEBGRB2IZEdmMcfHQeCtQUNmIrw+ViR2HiIiox7GMiEztpcDjNyYAAF7LPA2T2SJyIiIiop7FMuIEpo+NQ6CPAkXVTfjiYKnYcYiIiHoUy4gT8FPJMeemPgCA17efRhtHR4iIyIN0q4ysWLECcXFx8PLyQmpqKnJycq66/6uvvor+/fvD29sbMTExePrpp9Ha2tqtwO7q0bTeCPFToqS2BZ/nclVWIiLyHDaXkQ0bNmDhwoVYunQpDhw4gKSkJEyYMAGVlZWd7v/RRx9h0aJFWLp0KU6cOIHVq1djw4YNePbZZ687vDvxUV4aHXljewEMJrPIiYiIiHqGzWVk+fLlmD17NjIyMjBo0CCsXLkSPj4+WLNmTaf7//zzz7jhhhvw8MMPIy4uDrfffjumTJlyzdEUT/TImN4I9VehtL4Fn+zn6AgREXkGm8qI0WhEbm4u0tPTL30DqRTp6enIysrq9DVjx45Fbm6utXwUFhZiy5YtmDhx4nXEdk9eChnm3ZIIAFixvQCtbRwdISIi9ye3Zefq6mqYzWaEhYV12B4WFoaTJ092+pqHH34Y1dXVGDduHARBgMlkwpw5c656msZgMMBgMFj/W6/X2xLTpT2UEoOVO8+gXNeKj3OKkXFDvNiRiIiIHMrhV9Ps2LEDL730Ev7zn//gwIED2LhxIzZv3oy//e1vV3zNsmXLoNForI+YmBhHx3QaKrkM829tHx35z44zaDFydISIiNybTWUkJCQEMpkMFRUVHbZXVFQgPDy809c8//zzePTRRzFr1iwMHToU9913H1566SUsW7YMFkvnl7AuXrwYOp3O+igpKbElpst7MDkG0YHeqGow4MO958SOQ0RE5FA2lRGlUonk5GRkZmZat1ksFmRmZiItLa3T1zQ3N0Mq7fg2MpkMACAInd+LRaVSQa1Wd3h4EqVcij/c2hcAsHLnGTQZTCInIiIichybT9MsXLgQq1atwnvvvYcTJ05g7ty5aGpqQkZGBgBg2rRpWLx4sXX/SZMm4a233sL69etRVFSEbdu24fnnn8ekSZOspYQud9/IKPQO9kFNkxEfcHSEiIjcmE0TWAFg8uTJqKqqwpIlS6DVajF8+HBs3brVOqm1uLi4w0jIc889B4lEgueeew6lpaXo1asXJk2ahH/84x/2+xRuSCGTYv4tifjTZ4fx7k+FeGxsHLwULG9EROR+JMKVzpU4Eb1eD41GA51O51GnbNrMFtz88g6U1rdg6aRBvLKGiIhcSld/fvPeNE5MIZNi7s3tq7K+vbOQq7ISEZFbYhlxcr9LjkaYWgWtvhWf5/KOvkRE5H5YRpycl0KGJ25sHx35z44C3tGXiIjcDsuIC5iSEotgXyXO17Xgq7wyseMQERHZFcuIC/BWyjBrfAIAYMWPBTBbnH7OMRERUZexjLiIR9N6Q+OtQGF1E7YcKRc7DhERkd2wjLgIP5UcMy5c2vvm9gJYODpCRERugmXEhTw2Ng5+KjnyKxrww4mKa7+AiIjIBbCMuBCNjwLT0noDAN78seCK9/YhIiJyJSwjLmbmuHh4K2Q4fF6HnaeqxI5DRER03VhGXEywnwpTU2MBAG9s5+gIERG5PpYRFzT7xgQo5VLknqvD3sJaseMQERFdF5YRFxSm9sLkUTEAgDd/PC1yGiIiouvDMuKinrgpAXKpBHsKapB7rk7sOERERN3GMuKiogN98MDIaADAm9s5OkJERK6LZcSFzb25D6QS4Mf8Khwt1Ykdh4iIqFtYRlxYXIgv7k6KBACs3HlG5DRERETdwzLi4p64qQ8AYMuRcpTUNouchoiIyHYsIy5uYIQa4/uGwCIAa/YUiR2HiIjIZiwjbmD2+AQAwIZ9JdA1t4mchoiIyDYsI25gfN8QDAj3R7PRjP/mnBM7DhERkU1YRtyARCKxjo6s23MWBpNZ5ERERERdxzLiJiYlRSJMrUJlgwFf5ZWJHYeIiKjLWEbchFIuRcYN8QCAd38q4g30iIjIZbCMuJEpKbHwVcqQX9GAXaerxY5DRETUJSwjbkTjrcBDKbEAgFW7CkVOQ0RE1DUsI24m44Y4yKQS7C6oxrEyLhFPRETOj2XEzUQH+uCuoREA2ueOEBEROTuWETd08TLfrw+Voay+ReQ0REREV8cy4oaGRmswJiEIJouAdT+fFTsOERHRVbGMuKnHb2wfHfkouxj6Vi4RT0REzotlxE3d3C8UiaF+aDSYsCGnROw4REREV8Qy4qakUglmj29fBG3tniK0mS0iJyIiIuocy4gbu2d4FEL8VCjTtWLLkXKx4xAREXWKZcSNeSlkeGxsbwDAO7sKuUQ8ERE5JZYRNzc1tTe8FTIcK9Mj60yN2HGIiIguwzLi5gJ9lfifUdEAgHd+4hLxRETkfFhGPMCMcfGQSIAd+VXI1zaIHYeIiKgDlhEP0DvYF3cMDgcAvJ91VtwwREREv8Iy4iEeGdM+kfWrQ2VobTOLnIaIiOgSlhEPkZYQjKgAbzS0mvDdMa3YcYiIiKxYRjyEVCrBA8ntE1k/yz0vchoiIqJLWEY8yIMXysjugmqU8m6+RETkJFhGPEhMkA/GJARBEICNHB0hIiInwTLiYR5MjgEAfHbgPFdkJSIip8Ay4mHuHBoOP5Uc52qakVNUK3YcIiIilhFP46OU466hEQCAT3mqhoiInADLiAd68MLy8FuOlKPJYBI5DREReTqWEQ+U3DsQCSG+aDaasflIudhxiIjIw7GMeCCJ5BdrjuznqRoiIhIXy4iHemBkNKQSIOdsLc5WN4kdh4iIPBjLiIcK13hhfN9eALgiKxERiYtlxINdnMj6+YHzMFu45ggREYmDZcSDpQ8Mg8ZbgXJdK/YUVIsdh4iIPBTLiAfzUshwz/BIAFxzhIiIxMMy4uEuLg//3TEtdM1tIqchIiJP1K0ysmLFCsTFxcHLywupqanIycm54r4333wzJBLJZY+77rqr26HJfoZEqTEg3B9GkwVfHS4TOw4REXkgm8vIhg0bsHDhQixduhQHDhxAUlISJkyYgMrKyk7337hxI8rLy62Po0ePQiaT4cEHH7zu8HT9JBIJfmddc6RE5DREROSJbC4jy5cvx+zZs5GRkYFBgwZh5cqV8PHxwZo1azrdPygoCOHh4dbHtm3b4OPjwzLiRO4bEQW5VIJD53U4VdEgdhwiIvIwNpURo9GI3NxcpKenX/oGUinS09ORlZXVpe+xevVqPPTQQ/D19bUtKTlMsJ8Ktw4IBQB8ytERIiLqYTaVkerqapjNZoSFhXXYHhYWBq1We83X5+Tk4OjRo5g1a9ZV9zMYDNDr9R0e5FgPjmqfyPrFwVK0mS0ipyEiIk/So1fTrF69GkOHDkVKSspV91u2bBk0Go31ERMT00MJPdfN/XshxE+J6kYjfjzZ+fwfIiIiR7CpjISEhEAmk6GioqLD9oqKCoSHh1/1tU1NTVi/fj1mzpx5zfdZvHgxdDqd9VFSwlMHjqaQSXHfiCgAXHOEiIh6lk1lRKlUIjk5GZmZmdZtFosFmZmZSEtLu+prP/30UxgMBjzyyCPXfB+VSgW1Wt3hQY538VTNjycrUd1oEDkNERF5CptP0yxcuBCrVq3Ce++9hxMnTmDu3LloampCRkYGAGDatGlYvHjxZa9bvXo17r33XgQHB19/anKIfmH+SIrWwGQRsOlgqdhxiIjIQ8htfcHkyZNRVVWFJUuWQKvVYvjw4di6dat1UmtxcTGk0o4dJz8/H7t378b3339vn9TkML8bFYND53X4dP95zBwXD4lEInYkIiJycxJBEJz+dq16vR4ajQY6nY6nbBxM19yG0S/90L4i6/wbMCw6QOxIRETkorr685v3pqEOND4K3DG4fTLyqp+KRE5DRESegGWELjPnpj4AgG8Ol3FFViIicjiWEbrMoEg17hwSDkEAXss8LXYcIiJycywj1KkF6X0BAJsPl+OklivgEhGR47CMUKcGhKtx19AIAMBrP3B0hIiIHIdlhK5oQXpfSCTAt0e1OF7G0REiInIMlhG6on5h/pdGRzJPiZyGiIjcFcsIXdWC29pHR747VoFjZTqx4xARkRtiGaGr6hvmj7uTIgEAr3LuCBEROQDLCF3TH27rC6kE2Ha8AkfOc3SEiIjsi2WErqlPLz/cMzwKAPDqD5w7QkRE9sUyQl3y5K2JkEqAzJOVOFRSL3YcIiJyIywj1CUJvfxw7wiOjhARkf2xjFCX/eHWvpBJJfgxvwoHi+vEjkNERG6CZYS6LC7EF/dbR0d4ZQ0REdkHywjZ5Mlb+0IulWDnqSrknuPoCBERXT+WEbJJbLAPHhgZDYBzR4iIyD5YRshm829NhFwqwU+nq7H/bK3YcYiIyMWxjJDNYoJ88OCo9tGRf3N0hIiIrhPLCHXLvFsSoZBJsKegBjlFHB0hIqLuYxmhbokO9MH/jIoBAPx7G0dHiIio+1hGqNvm3ZIIpUyKrMIa7C2sETsOERG5KJYR6rbIAG9MHt0+OrJ82ykIgiByIiIickUsI3Rdfn9LHyhlUuQU1eKn09VixyEiIhfEMkLXJULjjUfTegMA/vbNcZjMFpETERGRq2EZoev2h1v7ItBHgdOVjfhvdrHYcYiIyMWwjNB10/go8Mfb+wNonztS12QUOREREbkSlhGyi4dGx2BAuD90LW1cJp6IiGzCMkJ2IZdJseS3gwAAH2YX41RFg8iJiIjIVbCMkN2MTQzBhMFhMFsE/O2b47zUl4iIuoRlhOzqLxMHQSmT4qfT1cg8USl2HCIicgEsI2RXscE+mDk+HgDw983HYTCZRU5ERETOjmWE7G7eLYno5a/C2ZpmvPfzWbHjEBGRk2MZIbvzU8nxzIT2S31fzyxAVYNB5EREROTMWEbIIR4YGY1h0Ro0Gkx45ft8seMQEZETYxkhh5BKJVg6qf1S3w37S3C0VCdyIiIiclYsI+Qwyb2DcM/wSAgC8Nevj/FSXyIi6hTLCDnUn+8YAC+FFPvO1mHzkXKx4xARkRNiGSGHigzwxpyb+gAAlm05idY2XupLREQdsYyQwz1xYx9EarxQWt+Cd3YVih2HiIicDMsIOZy3UoZFEwcCAN7acQbluhaRExERkTNhGaEeMWlYBEb1DkRLmxn/+vak2HGIiMiJsIxQj5BIJFg6aTAkEmBTXhlyz9WJHYmIiJwEywj1mKHRGjyYHA0AePHrY7BYeKkvERGxjFAP+38T+sNPJceh8zpsPFgqdhwiInICLCPUo0L9vTD/1kQAwD+/PYnqRt63hojI07GMUI/LuCEOiaF+qG40YP5HB2AyW8SOREREImIZoR6nksuw8pGR8FXKsLewFv/7HW+kR0TkyVhGSBSJof54+cEkAMA7uwqxhUvFExF5LJYREs3EoRF4/MYEAMCfPj2EgsoGkRMREZEYWEZIVM9M6I8xCUFoMprx+Ae5aGhtEzsSERH1MJYREpVcJsWbD49EuNoLhVVNeOazwxAErj9CRORJWEZIdCF+KvznkZFQyCT49qiWN9MjIvIwLCPkFEbGBmLppMEAgH9tPYmfC6pFTkRERD2FZYScxtTUWDwwMhoWAXjy44Moq+fdfYmIPAHLCDkNiUSCf9w3BIMi1KhpMmLufw/AYDKLHYuIiByMZYScipdChrcfTYbGW4FDJfX469fHxY5EREQO1q0ysmLFCsTFxcHLywupqanIycm56v719fWYN28eIiIioFKp0K9fP2zZsqVbgcn9xQT54LWHhkMiAT7KLsYn+0vEjkRERA5kcxnZsGEDFi5ciKVLl+LAgQNISkrChAkTUFlZ2en+RqMRv/nNb3D27Fl89tlnyM/Px6pVqxAVFXXd4cl93dw/FE+n9wMAPLfpKI6W6kROREREjiIRbFzUITU1FaNHj8abb74JALBYLIiJicGTTz6JRYsWXbb/ypUr8fLLL+PkyZNQKBTdCqnX66HRaKDT6aBWq7v1Pcj1WCwCZr+/H5knKxEd6I2v549DoK9S7FhERNRFXf35bdPIiNFoRG5uLtLT0y99A6kU6enpyMrK6vQ1X331FdLS0jBv3jyEhYVhyJAheOmll2A2X3liosFggF6v7/AgzyOVSrB88nD0DvbB+boWLNiQB7OFC6IREbkbm8pIdXU1zGYzwsLCOmwPCwuDVqvt9DWFhYX47LPPYDabsWXLFjz//PN45ZVX8Pe///2K77Ns2TJoNBrrIyYmxpaY5EY03gqsfCQZXgopdp2qwms/nBI7EhER2ZnDr6axWCwIDQ3FO++8g+TkZEyePBl/+ctfsHLlyiu+ZvHixdDpdNZHSQknMHqygRFq/PP+YQCA17cX4PtjnRdfIiJyTTaVkZCQEMhkMlRUVHTYXlFRgfDw8E5fExERgX79+kEmk1m3DRw4EFqtFkajsdPXqFQqqNXqDg/ybPeOiMJjY+MAAPM/Pohdp6rEDURERHZjUxlRKpVITk5GZmamdZvFYkFmZibS0tI6fc0NN9yAgoICWCwW67ZTp04hIiICSiUnI1LX/eWugbh9UBiMJgtmv78fu09zyXgiIndg82mahQsXYtWqVXjvvfdw4sQJzJ07F01NTcjIyAAATJs2DYsXL7buP3fuXNTW1mLBggU4deoUNm/ejJdeegnz5s2z36cgj6C4cIff9IFhMJgsmPX+Pt7DhojIDchtfcHkyZNRVVWFJUuWQKvVYvjw4di6dat1UmtxcTGk0ksdJyYmBt999x2efvppDBs2DFFRUViwYAH+/Oc/2+9TkMdQyqVYMXUE5n54ANtPVmLGe/uwLiMFYxKCxY5GRETdZPM6I2LgOiP0awaTGU98kIsd+VXwVsjw3owUpMQHiR2LiIh+wSHrjBA5C5VchpWPJGN83xC0tJnx2Noc7D9bK3YsIiLqBpYRclleChlWTRuFcYkhaDaaMX1NDnLP1Ykdi4iIbMQyQi7tYiEZ2ycYTRcKycFiFhIiIlfCMkIuz1spw7vTR2FMQhAaDSZMW52DQyX1YsciIqIuYhkht+CjlGPNY6OREheEBoMJj67OxpHzvNMvEZErYBkht+GjlGNtxmiM6h0IfasJj6zOxtFSFhIiImfHMkJuxVclx7oZKRgZGwBdSxseWZ2N42W86zMRkTNjGSG346eS470ZKRgeE4D65jZMfXcvTmpZSIiInBXLCLklfy8F3puRgmHRGtQ1t2HqqmycqmgQOxYREXWCZYTclsZbgQ9mpGJIlBo1TUZMfjsL/9p6EifK9XCBhYeJiDwGl4Mnt1ffbLwwmfXSqZq+oX6YlBSJu5MiERfiK2I6IiL31dWf3ywj5BEMJjN+OF6Jrw6V4sf8KhhNFutzw6I1mDQsEr9NikCExlvElERE7oVlhOgK9K1t+P5YBb46VIY9BdUwW9r/CkgkwOi4IExKisTEIeEI9lOJnJSIyLWxjBB1QU2jAVuOavF1XhlyfnGjPZlUgnGJIZiUFIkJg8Pg76UQMSURkWtiGSGyUVl9CzYfLsdXh8pw5BeLpSnlUtzaPxTzbknE0GiNiAmJiFwLywjRdSisasQ3F4pJQWUjAMBXKcNHs8cgKSZA3HBERC6CZYTIDgRBwInyBrz4zTHsLaxFgI8CGx5PQ/9wf7GjERE5va7+/OY6I0RXIZFIMChSjXenj7au6Pro6mycq2kSOxoRkdtgGSHqAj+VHOsyRmNAuD8qGwyY+m42tLpWsWMREbkFlhGiLgrwUeL9mSmIC/bB+boWPLI6GzWNBrFjERG5PJYRIhuE+nvhw1mpiNB4oaCyEdPX5kDf2iZ2LCIil8YyQmSj6EAffDAzFcG+Shwt1WPWuv1oMZrFjkVE5LJYRoi6ITHUD+/NSIG/lxw5Z2sx58PcDkvMExFR17GMEHXTkCgN1j42Gl4KKXaeqsLTG/KsS8sTEVHXsYwQXYdRcUF4+9FRUMgk2HykHM9uPAIXWLqHiMipsIwQXaeb+vXC6w+NgFQCbNhfgr9vPsFCQkRkA5YRIju4c2gE/vXAMADA6t1FeD2zQORERESug2WEyE4eHBWDpZMGAQD+/cMprNldJHIiIiLXwDJCZEcZN8Rj4W/6AQBe/OY4PtlXInIiIiLnxzJCZGdP3pqI2ePjAQCLNh7GliPlIiciInJuLCNEdiaRSPDsxIF4aHQMLAKwYP1B7MivFDsWEZHTYhkhcgCJRIJ/3DcUvx0WgTazgDkf5iKnqFbsWERETollhMhBZFIJlv/PcNzSvxda2yyYtiYbL3x1DOfrmsWORkTkVFhGiBxIKZfirUeScWO/9kKy7uezuOnlHXh6Qx5OavVixyMicgoSwQVWZ9Lr9dBoNNDpdFCr1WLHIbKZIAjYXVCNlTvPYE9BjXX7Lf17Yc5NfZASHwSJRCJiQiIi++vqz2+WEaIedvh8Pd7eWYhvj5bj4q1sRsQGYM5NffCbgWGQSllKiMg9sIwQObmz1U1456dCfJZ73nrH3z69fPHEjX1w74goKOU8i0pEro1lhMhFVDa0Yt2es/hg7zk0tJoAAGFqFWaOi8eUlFj4eylETkhE1D0sI0QupqG1DR/nFGP17iJU6A0AAH8vOR4d0xsZN8Sjl79K5IRERLZhGSFyUQaTGV8eLMPKXWdQWNUEoP2qnN8lR+Px8QmIC/EVOSERUdewjBC5OItFwLYTFXhrxxnkldRbt0cHemNghBoDI9QYFOGPgRFqxAT6cOIrETkdlhEiNyEIArKLarFy5xnsyK/qdB9fpQwDItQYeKGcDIxQY0C4P3yU8h5OS0R0CcsIkRvSNbfhhFaPE+Xtj+PlepyqaLRejfNLEgkQH+x7oZxcKikRGi+uaUIOZbEIyCqswYBwfwT7ca6TJ2MZIfIQJrMFhdVN1nJyorwBx8v0qG40dLq/xluBQRFqzLslEeP6hvRwWnJ3bWYL/vTpIWzKK0OQrxKvPJiEWwaEih2LRMIyQuThqhoM1hGUExdKSkFVI8wXVlpTyCR4+9Fk3DogTOSkHeUU1UIhk2BolAZyGddacSWtbWb8/r8HsP1kx7tUzx4fjz9NGMC1czwQywgRXaa1zYyCykas+LEA3x7VQimTYtX0UbipXy+xo0EQBPzvd/l4a8cZAICfSo6U+CCM7ROMMQnBGBSh5iRdJ6ZracPs9/Yj52wtvBRSvPbQCGSdqcG6n88CAIZFa/DGlBHoHcyrwTwJywgRXVGb2YInPzqIrce0UMqlWDN9tKinbNrMFizeeASf5Z4H0L6+ysUF4C4K8FEgNT4IY/uEIK1PMPqG+nHui5OoajBg+pocHC/Xw99LjjWPjcbouCAAwPfHtPjTZ4eha2mDn0qOZfcPxaSkSJETU09hGSGiqzKaLPj9fw/ghxMV8FJIseax0Rjbp+cLSbPRhHn/PYAf86sglQDL7h+K3yXH4ES5HllnapBVWIPswho0Gc0dXhfip8KYhEvlJC7Yh+VEBCW1zXh0dTbO1jQjxE+F92ekYFBkx/9Pl9W34A8fH8T+c3UAgCkpMVjy28HwVsrEiEw9iGWEiK7JYDJj7oft5/i9FTKsyxiN1ITgHnv/uiYjMtbtQ15JPVRyKVY8PBLpgy6fw9JmtuBIqa69nJypwf5ztWht63gFUYTGC2l9gpGWEIy0PsGIDvTpqY/hsU5XNODR1TnQ6lsRHeiND2emXnFRPpPZgtcyT+PNHwsgCEDfUD+8+fBI9A/37+HU9Gtnq5uw9ZgWc27qY/fvzTJCRF3S2mbGEx/kYuepKvgoZXh/RgpGXRhid6TS+hZMW52NM1VN0HgrsOaxUUju3bX3NZjMyCuuR1ZhDX4+U4O84noYzR3LSWyQD8b2CbYWlFC1lyM+hsfKK6nHY2tzUN/chr6hfvhgZirCNdc+xnsKqvHUhjxUNRigkkvxwt2D8dDoGI5qiSD3XC3e2VWI749XQBCAz+emdfnvYFexjBBRl7W2mTH7/f346XQ1fJUyvD8zFcm9Ax32fie1ekxfk4MKvQERGi+8PyMFfcO6/y/kFqMZuefqkFVYjZ/P1ODweZ31qqGLbu7fC3+7Zwhigjhicr32FFRj9vv70Ww0IykmAOseG41AX2WXX1/daMDCTw5h16n2RfzuGhaBZfcPhZo3hXQ4s0XA98e0eOenQhwsrrduv6V/L/y/Cf0xOFJj1/djGSEim7QYzZixbh+yCmvgr5Ljg1mpGB4TYPf3ySmqxcz39qGh1YS+oX54b0YKIgO87foejQYT9hXV4ucz1cgqrMGxMj0EAfBRyvD/bu+P6WPjIOOVOd2y9agWf/j4IIxmC8YlhuDtR5Phq7J9pV+LRcCqnwrx8nf5MFkExAR5440pIx3yZ47a52Z9uv88Vu8uQnFtMwBAKZPi/pFRmDku/rr+MXA1LCNEZLNmowmPrd2HnKJa+HvJ8dGsMRgabb9/KX13TIsnPz4Io8mCUb0D8e70UQjw6fq/qLvrTFUjFn9+BDlnawEAI2ID8K8HhqGfg/4H7K4+2VeCRRsPwyIAdw4Jx6sPDYdKfn2TUA8U1+EPHx/E+boWyKUS/PmOAZg5Lp6XcdtJpb4V72WdxYd7i6FraQPQfmXao2N649G03gj1d+zpS5YRIuqWJoMJ09fkYP+5Omi8Ffhodqpdhm4/yi7Gc5uOwCIA6QND8caUkT16NYXFIuCjnGL889uTaDSYoJBJ8PubE/H7W/pc9w9UT7BqVyH+seUEAGDyqBi8dP9Qu40u6VrasHjjYWw5ogXQfkrtlQeTuJT8dcjXNuDdnwrxZV6ZdT5VXLAPZo5PwO9GRvfY3z2WESLqtkaDCdNWZ+NAcT0CfRT4aPYYDIzo3t89QRDwemYB/v3DKQDtP8j+cd8Q0VZXLde14PlNR/HDifZVQvuG+uFfvxuGkbGOmyPjygRBwP99n48VP7YvRvfETQlYdMcAu084FYT2svji18dhMFkQ6q/Cqw8NF+Vyc1clCAL2FNRg1U+F2Hnq0k01R/UOxKzxCfjNoLAePz3JMkJE10Xf2oZHV+fgUEk9gnyV+Hj2GJsvwzRbBCz58ij+m10MAHjy1kQs/E0/0a+cEAQBm4+U44WvjqG60QiJBJieFoc/TejfrfkP7spsEfD8l0fx0YXfvz/fMQBzb7b/5Z+/dFKrx/yPDqKgshESCfDkrX3xh1sTeWuAqzCaLPjmcBlW/VSEE+V6AIBUAtwxJByzxieIWrQdWkZWrFiBl19+GVqtFklJSXjjjTeQkpLS6b7r1q1DRkZGh20qlQqtra1dfj+WESJx6Fra8Mi72ThSqkOInxLrHx+DxNCuFZLWNjOeWp+Hrce0kEiAv949GNPS4hwb2EZ1TUb8ffMJfH6gfeXXqABvvHT/UKdYHl9sRpMFT3+Sh82HyyGRAC/dNxRTUmJ75L2bjSb89avj2LC/BACQEheE16YMR4TGvhOdXZ2upQ0f5xRj3Z6z0Orbf6Z6K2SYPDoGM26IR2yw+FeOOayMbNiwAdOmTcPKlSuRmpqKV199FZ9++iny8/MRGnr5nRnXrVuHBQsWID8//9KbSiQIC+v6zblYRojEU99sxMOrsnG8XI9e/iqsf3wM+vTyu+prdC1tePz9/cguqoVSJsWrDw3HxKERPZTYdrtOVeHZL47gfF0LAOD+EVF4/reDbLpc1Z00G02Y8+EB7DpVBYVMglcnj8Bdw3r+9+/LvFI8u/EImoxmBPgo8H+/S+p0UTxPc76uGWv3nMX6nGLrysS9/FV4bGwcpqbG9sik8K5yWBlJTU3F6NGj8eabbwIALBYLYmJi8OSTT2LRokWX7b9u3To89dRTqK+vt+0T/ALLCJG46pqMmLJqL05qGxCmVmHD42lXXGmzQt+K6WtycFLbAH+VHG9PS3aJ8/5NBhNe+f4U1v5cBEEAgn2VWHr3YEwaFiH6aaWepGtuQ8a6HBworoe3Qoa3H03GjSKOFJ2tbsL8jw/gaGn76YeMG+Kw6M4BDpl03Ggw4XxdM0pqWzp+rWtBhb4VAT4KRAf6ICrAG9GB7Y/2X/sg1F/l8CuADp+vxzu7CvHtUa11HZ1+YX6YPT4Bdw+PdMqJ2A4pI0ajET4+Pvjss89w7733WrdPnz4d9fX1+PLLLy97zbp16zBr1ixERUXBYrFg5MiReOmllzB48OArvo/BYIDBYOjwYWJiYlhGiERU02jAlFV7caqiEREaL2x4PO2yYeAzVY2YtjoHpfUt6OWvwrqM0XZfRMnRDhbXYdHnR5Bf0QAAuG1AKP527xC7r4XijCr1rZh2oUi2r4o72qGL33WVwWTG/27Nx+rdRQCAIVFqvDFlJOKvUIivpMVoRml9x5Lxy9JR19zW7YwKmQQRmo4FJcr6a29EaLy6Ne/FYhGw/WQl3vmpEDlFtdbt4xJDMPvGBNzYN8Spy7JDykhZWRmioqLw888/Iy0tzbr9mWeewc6dO5GdnX3Za7KysnD69GkMGzYMOp0O//d//4ddu3bh2LFjiI6O7vR9XnjhBfz1r3+9bDvLCJG4qhoMeOidLJypakJUgDfWPz7GuqLpweI6zFi3D3XNbYgP8cX7M1JcdrVTo8mCt3acwZs/nkabWYCfSo4/3zkAU1Ni3Xb9i+KaZjyyOhvFtc0I9Vfhg5mpTnffmMwTFfjjp4dQ39wGX6UML90/FPcMj7I+bzCZUVrXgvN1LSipa27/Wtv+9XxdM6objdd8jwAfBWICfRAd6I2YIB/EBLYXizC1F+qbjThf3/79S+taUFrf/r3Lda2Xrfj7a1IJEKFpLydRgZeXlsgArw4jG61tZmw8UIp3dxeisKoJACCXSnB3UiRmjo93mZLvNGXk19ra2jBw4EBMmTIFf/vb3zrdhyMjRM6rUt+Kh97Zi8LqJkQHemPDE2k4VdGA3394AC1tZgyL1mDtY6PdYo2I0xUN+PPnh3HgwrLZo+MCsez+YUgMvfqcGVdzUqvHtNU5qGwwIDbIBx/OTHWKyY+dKde1YMHHedYF7Mb2CYbRZEFJXTMqGwy41k80f5Uc0UEXysYvSsfF0y7+3ViS3mS2oKLBcKEINV8oKhdKS317cfn1vZM6E+qvQtSFUZTswlrUNLWXJ38vOR5OjcVjY+NcbhKv05ym6cyDDz4IuVyOjz/+uEv7c84IkXPR6lrx0DtZOFvTjDC1CjWNRpgsAm7s1wtvTR3pVpfHmi0CPsg6i//9Lh/NRjOUMin+cFsinripDxRucLlp7rk6ZKzNgb7VhAHh/nh/RorT31TQZLbgje0FeH376cvKh7dChpig9hGHi6Mal/7bB2pveY+f1rBYBFQ3GlDyi3Jyvq75UmGpa0FLm/my10UFeGPGuHhMHh0DPxf9O+XQCawpKSl44403ALRPYI2NjcX8+fM7ncD6a2azGYMHD8bEiROxfPnyLr0nywiR8ynXtWDy23ut97m4b0QU/vXAMCjlrv8DujOl9S34yxdHsCO/fTGpAeH++N/fDcOw6AAA7WuXtJkFGM0WGNrMF75afvHVDEObBYYO2y/tZzBZYDRZYDCZYTRZYBYEBPooEeynRLCv6sJXJYL9VFB72ecH6q5TVXjig1y0tJkxMjYAax9LgcbHdW5Wd6ikHvvO1iJM7WU9pRLkq3TqORSdEQQBtU1Gazkpq29BVIA3fjMozOXXV3Hopb3Tp0/H22+/jZSUFLz66qv45JNPcPLkSYSFhWHatGmIiorCsmXLAAAvvvgixowZg8TERNTX1+Pll1/Gpk2bkJubi0GDBtn1wxBRzyqtb1/NdHhMAObfkui28ykuEgQBm/JK8eLXx1HX3AapBPBTyduLhNlyzVME9qKQSRDke6mkhPip2v/bT4mQC9uCfNu3B/sp4aO8/F/Vmw+X46kNB9Fmbh/RWvnIyE73I7oeXf35bfOfvMmTJ6OqqgpLliyBVqvF8OHDsXXrVuu6IcXFxZBKLzW5uro6zJ49G1qtFoGBgUhOTsbPP//c5SJCRM4rKsAbax4bLXaMHiORSHDfiGjc2LcXXvzmOL7MK4O+1dTpvkqZFEq5FCr5r7/KLtt++TYZJJL2NV6qG42oaTSgtsmImkYjGgwmtJkFVOgNqNAbOn3vX/NWyC6Uk/aRFR+lDJuPlEMQgN8Oi8Dy/xnutiNa5Bq4HDwRUTeV1begtc18ecmQSR02StTaZkZtkxG1TUZUNxpQ02hETZMBNRfKSk3jpV9XNxpgMF154uTU1Fi8eM+QHr9fCXkOh42MEBFROzHWHvFSyBAZ4N2l9xYEAc1G86XCcuFrdaMRvYN9cNdQz1rQjZwXywgRkZuSSCTwVcnhq5I77aW6RADAk4REREQkKpYRIiIiEhXLCBEREYmKZYSIiIhExTJCREREomIZISIiIlGxjBAREZGoWEaIiIhIVCwjREREJCqWESIiIhIVywgRERGJimWEiIiIRMUyQkRERKJyibv2CoIAANDr9SInISIioq66+HP74s/xK3GJMtLQ0AAAiImJETkJERER2aqhoQEajeaKz0uEa9UVJ2CxWFBWVgZ/f39IJJLr/n56vR4xMTEoKSmBWq22Q0K6Eh7rnsNj3XN4rHsOj3XPccSxFgQBDQ0NiIyMhFR65ZkhLjEyIpVKER0dbffvq1ar+Ye7h/BY9xwe657DY91zeKx7jr2P9dVGRC7iBFYiIiISFcsIERERicojy4hKpcLSpUuhUqnEjuL2eKx7Do91z+Gx7jk81j1HzGPtEhNYiYiIyH155MgIEREROQ+WESIiIhIVywgRERGJimWEiIiIROVxZWTFihWIi4uDl5cXUlNTkZOTI3Ykl7Nr1y5MmjQJkZGRkEgk2LRpU4fnBUHAkiVLEBERAW9vb6Snp+P06dMd9qmtrcXUqVOhVqsREBCAmTNnorGxsQc/hWtYtmwZRo8eDX9/f4SGhuLee+9Ffn5+h31aW1sxb948BAcHw8/PDw888AAqKio67FNcXIy77roLPj4+CA0NxZ/+9CeYTKae/ChO76233sKwYcOsCz6lpaXh22+/tT7P4+wY//znPyGRSPDUU09Zt/FY288LL7wAiUTS4TFgwADr805zrAUPsn79ekGpVApr1qwRjh07JsyePVsICAgQKioqxI7mUrZs2SL85S9/ETZu3CgAEL744osOz//zn/8UNBqNsGnTJuHQoUPC3XffLcTHxwstLS3Wfe644w4hKSlJ2Lt3r/DTTz8JiYmJwpQpU3r4kzi/CRMmCGvXrhWOHj0q5OXlCRMnThRiY2OFxsZG6z5z5swRYmJihMzMTGH//v3CmDFjhLFjx1qfN5lMwpAhQ4T09HTh4MGDwpYtW4SQkBBh8eLFYnwkp/XVV18JmzdvFk6dOiXk5+cLzz77rKBQKISjR48KgsDj7Ag5OTlCXFycMGzYMGHBggXW7TzW9rN06VJh8ODBQnl5ufVRVVVlfd5ZjrVHlZGUlBRh3rx51v82m81CZGSksGzZMhFTubZflxGLxSKEh4cLL7/8snVbfX29oFKphI8//lgQBEE4fvy4AEDYt2+fdZ9vv/1WkEgkQmlpaY9ld0WVlZUCAGHnzp2CILQfW4VCIXz66afWfU6cOCEAELKysgRBaC+PUqlU0Gq11n3eeustQa1WCwaDoWc/gIsJDAwU3n33XR5nB2hoaBD69u0rbNu2TbjpppusZYTH2r6WLl0qJCUldfqcMx1rjzlNYzQakZubi/T0dOs2qVSK9PR0ZGVliZjMvRQVFUGr1XY4zhqNBqmpqdbjnJWVhYCAAIwaNcq6T3p6OqRSKbKzs3s8syvR6XQAgKCgIABAbm4u2traOhzvAQMGIDY2tsPxHjp0KMLCwqz7TJgwAXq9HseOHevB9K7DbDZj/fr1aGpqQlpaGo+zA8ybNw933XVXh2MK8M+0I5w+fRqRkZFISEjA1KlTUVxcDMC5jrVL3CjPHqqrq2E2mzscUAAICwvDyZMnRUrlfrRaLQB0epwvPqfVahEaGtrheblcjqCgIOs+dDmLxYKnnnoKN9xwA4YMGQKg/VgqlUoEBAR02PfXx7uz34+Lz9ElR44cQVpaGlpbW+Hn54cvvvgCgwYNQl5eHo+zHa1fvx4HDhzAvn37LnuOf6btKzU1FevWrUP//v1RXl6Ov/71rxg/fjyOHj3qVMfaY8oIkaubN28ejh49it27d4sdxW31798feXl50Ol0+OyzzzB9+nTs3LlT7FhupaSkBAsWLMC2bdvg5eUldhy3d+edd1p/PWzYMKSmpqJ379745JNP4O3tLWKyjjzmNE1ISAhkMtlls4QrKioQHh4uUir3c/FYXu04h4eHo7KyssPzJpMJtbW1/L24gvnz5+Obb77Bjz/+iOjoaOv28PBwGI1G1NfXd9j/18e7s9+Pi8/RJUqlEomJiUhOTsayZcuQlJSE1157jcfZjnJzc1FZWYmRI0dCLpdDLpdj586deP311yGXyxEWFsZj7UABAQHo168fCgoKnOrPtceUEaVSieTkZGRmZlq3WSwWZGZmIi0tTcRk7iU+Ph7h4eEdjrNer0d2drb1OKelpaG+vh65ubnWfbZv3w6LxYLU1NQez+zMBEHA/Pnz8cUXX2D79u2Ij4/v8HxycjIUCkWH452fn4/i4uIOx/vIkSMdCuC2bdugVqsxaNCgnvkgLspiscBgMPA429Ftt92GI0eOIC8vz/oYNWoUpk6dav01j7XjNDY24syZM4iIiHCuP9d2mwrrAtavXy+oVCph3bp1wvHjx4XHH39cCAgI6DBLmK6toaFBOHjwoHDw4EEBgLB8+XLh4MGDwrlz5wRBaL+0NyAgQPjyyy+Fw4cPC/fcc0+nl/aOGDFCyM7OFnbv3i307duXl/Z2Yu7cuYJGoxF27NjR4dK85uZm6z5z5swRYmNjhe3btwv79+8X0tLShLS0NOvzFy/Nu/3224W8vDxh69atQq9evXgZ5K8sWrRI2Llzp1BUVCQcPnxYWLRokSCRSITvv/9eEAQeZ0f65dU0gsBjbU9//OMfhR07dghFRUXCnj17hPT0dCEkJESorKwUBMF5jrVHlRFBEIQ33nhDiI2NFZRKpZCSkiLs3btX7Egu58cffxQAXPaYPn26IAjtl/c+//zzQlhYmKBSqYTbbrtNyM/P7/A9ampqhClTpgh+fn6CWq0WMjIyhIaGBhE+jXPr7DgDENauXWvdp6WlRfj9738vBAYGCj4+PsJ9990nlJeXd/g+Z8+eFe68807B29tbCAkJEf74xz8KbW1tPfxpnNuMGTOE3r17C0qlUujVq5dw2223WYuIIPA4O9KvywiPtf1MnjxZiIiIEJRKpRAVFSVMnjxZKCgosD7vLMdaIgiCYL9xFiIiIiLbeMycESIiInJOLCNEREQkKpYRIiIiEhXLCBEREYmKZYSIiIhExTJCREREomIZISIiIlGxjBAREZGoWEaIiIhIVCwjREREJCqWESIiIhIVywgRERGJ6v8DEXQLck0ZTWcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds_bool = np.empty_like(y_actual)\n",
    "l_arr = np.array(range(501))\n",
    "errors = np.zeros_like(l_arr)\n",
    "samples = np.zeros_like(l_arr)\n",
    "for idx in range(y_actual.size):\n",
    "    samples[l1[idx]] += 1\n",
    "    y_pred = y_prob[idx] > 0.5\n",
    "    y_preds_bool[idx] = y_pred\n",
    "    if (y_pred != y_actual[idx]) :\n",
    "        errors[l1[idx]] += 1\n",
    "\n",
    "comp_list = np.equal(y_preds_bool, y_actual).astype('float')\n",
    "comparison = []\n",
    "for n in range(max(l1)):\n",
    "    comparison.append([])\n",
    "for n in range(len(comp_list)):\n",
    "    idx = l1[n] - 1\n",
    "    comparison[idx].append(comp_list[n])\n",
    "stats_dict = calc_stats(comparison, n_sampling=5000, x0_max=10, verbose=True)\n",
    "fidelity = np.divide(samples - errors, samples, out=np.zeros_like(errors, dtype=float), where=(samples != 0)).astype(float)\n",
    "\n",
    "x, y = [], []\n",
    "for idx in range(len(fidelity)):\n",
    "    if (fidelity[idx] != 0):\n",
    "        x.append(l_arr[idx])\n",
    "        y.append(fidelity[idx])\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylabel(\"Logical Fidelity\")\n",
    "plt.xlabel(\"Cycles\")\n",
    "\n",
    "print(f\"Overall Accuracy: {1 - np.sum(errors) / np.sum(samples)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
